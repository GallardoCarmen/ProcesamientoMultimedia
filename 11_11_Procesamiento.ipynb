{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQkR2ziTFKYgnAnulPSJ5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GallardoCarmen/ProcesamientoMultimedia/blob/main/11_11_Procesamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTwZtpoZVz41"
      },
      "outputs": [],
      "source": [
        "#import cv2\n",
        "import numpy as np\n",
        "#from google.colab.patches import cv2_imshow  # For displaying images in Colab\n",
        "\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print(\"gray elements:\",gray.shape)\n",
        "\n",
        "# Step 1: Apply Gaussian blur to reduce noise\n",
        "blurred = cv2.GaussianBlur(gray, (15, 15), 5)\n",
        "\n",
        "\n",
        "blurred_display = cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR)\n",
        "cv2_imshow(\"image\",blurred_display)  # Display the binary image\n",
        "\n",
        "\n",
        "# Step 2: Apply binary thresholding to create a binary image\n",
        "_, binary = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "binary=binary #~binary\n",
        "\n",
        "# Convert binary image to 3 channels for display\n",
        "binary_display = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
        "cv2_imshow(\"image\",binary_display)  # Display the binary image\n",
        "\n",
        "# Step 3: Use morphological operations to fill in small holes or gaps in the coins\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "Kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(10,10))\n",
        "morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "\n",
        "# Convert binary image to 3 channels for display\n",
        "morph_display = cv2.cvtColor(morph, cv2.COLOR_GRAY2BGR)\n",
        "cv2_imshow(\"image\",morph_display)  # Display the binary image\n",
        "\n",
        "# Step 4: Find contours of the shapes\n",
        "contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Step 5: Filter contours by area to remove small artifacts\n",
        "min_area = 200  # Minimum area threshold; adjust as needed based on image size\n",
        "coin_count = 0  # Counter for coins detected\n",
        "\n",
        "for contour in contours:\n",
        "    area = cv2.contourArea(contour)\n",
        "    if area > min_area:\n",
        "        # Draw contour on the original image\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.drawContours(morph_display, [contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "        # Add a label on top of the coin\n",
        "        label = f\"Coin {coin_count}\"\n",
        "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "        coin_count += 1\n",
        "\n",
        "# Display the original image with detected contours highlighted\n",
        "cv2_imshow(\"image\", morph_display)\n",
        "\n",
        "# Print the number of detected coins\n",
        "print(\"Number of coins detected:\", coin_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install opencv_jupyter_ui\n",
        "!pip install -q ipycanvas==0.11\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import opencv_jupyter_ui as jcv2\n",
        "\n",
        "roi = cv2.imread(\"matricula.webp\")\n",
        "jcv2.imshow(\"car\", roi)\n",
        "cargray = cv2.cvtColor (roi, cv2.COLOR_BGR2GRAY)\n",
        "carblur = cv2.blur(cargray, (5,5))\n",
        "jcv2.imshow(\"car\", carblur)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EuclideanDistTracker:\n",
        "    def __init__(self):\n",
        "        self.center_points = {}\n",
        "        self.id_count = 0\n",
        "\n",
        "    def update(self, objects_rect):\n",
        "        objects_bbs_ids = []\n",
        "        for rect in objects_rect:\n",
        "            x, y, w, h = rect\n",
        "            cx = (x + x + w) // 2\n",
        "            cy = (y + y + h) // 2\n",
        "            same_object_detected = False\n",
        "            for id, pt in self.center_points.items():\n",
        "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
        "                if dist < 25:\n",
        "                    self.center_points[id] = (cx, cy)\n",
        "                    objects_bbs_ids.append([x, y, w, h, id])\n",
        "                    same_object_detected = True\n",
        "                    break\n",
        "            if not same_object_detected:\n",
        "                self.center_points[self.id_count] = (cx, cy)\n",
        "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
        "                self.id_count += 1\n",
        "\n",
        "        new_center_points = {}\n",
        "        for obj_bb_id in objects_bbs_ids:\n",
        "            _, _, _, _, object_id = obj_bb_id\n",
        "            center = self.center_points[object_id]\n",
        "            new_center_points[object_id] = center\n",
        "        self.center_points = new_center_points.copy()\n",
        "        return objects_bbs_ids\n",
        "\n",
        "tracker = EuclideanDistTracker()\n",
        "min_width = 10\n",
        "min_height = 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"highway_traffic.mp4\")\n",
        "\n",
        "# Check if camera opened successfully\n",
        "if (cap.isOpened()== False):\n",
        "    print(\"Error opening video file\")\n",
        "\n",
        "# Create tracker object\n",
        "tracker = EuclideanDistTracker()\n",
        "\n",
        "backeraser=cv2.createBackgroundSubtractorMOG2()#(history=100, varThreshold=40);\n",
        "# Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "\n",
        "# Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "   #Show the image with matplotlib\n",
        "        frame=cv2.resize(frame,(320,240));\n",
        "        mask=backeraser.apply(frame);\n",
        "        #plt.imshow(frame)\n",
        "        #plt.show()\n",
        "        # Extract Region of interest\n",
        "        #roi = frame[340: 720,500: 800]\n",
        "\n",
        "\n",
        "        _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        detections = []\n",
        "        for cnt in contours:\n",
        "          # Calculate area and remove small elements\n",
        "          area = cv2.contourArea(cnt)\n",
        "          if area > 100:\n",
        "              #cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
        "              x, y, w, h = cv2.boundingRect(cnt)\n",
        "              detections.append([x, y, w, h])\n",
        "\n",
        "              # 2. Object Tracking\n",
        "          boxes_ids = tracker.update(detections)\n",
        "          for box_id in boxes_ids:\n",
        "            x, y, w, h, id = box_id\n",
        "            cv2.putText(frame, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Press Q on keyboard to exit\n",
        "\n",
        "        jcv2.imshow(\"Frame\",frame)\n",
        "    if jcv2.waitKey(25) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "# When everything done, release\n",
        "# the video capture object\n",
        "cap.release()\n",
        "\n",
        "# Closes all the frames\n",
        "jcv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fawt8WoiWLv4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}